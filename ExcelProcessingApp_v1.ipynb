{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1f7d46e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting process_funcs.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile process_funcs.py\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "\n",
    "def process_excel_files(file_names, pattern):\n",
    "    all_df = []\n",
    "\n",
    "    for file_name in file_names:\n",
    "        course_id = extract_pattern(str(file_name), pattern) \n",
    "        df = pd.read_excel(file_name, sheet_name='UBYS', header=1)\n",
    "        \n",
    "        # Add the \"Course\" column to the DataFrame\n",
    "        df.insert(0, \"Ders\", course_id)\n",
    "        all_df.append(df)\n",
    "\n",
    "    return all_df\n",
    "\n",
    "def preprocess_data(df):\n",
    "\n",
    "    # Remove the last two columns\n",
    "    df = df.iloc[:, :-2]\n",
    "\n",
    "    # Drop rows where the second column is NaN\n",
    "    df = df.dropna(subset=[df.columns[2]])\n",
    "\n",
    "    # Select only the columns\n",
    "    cols = ['Ders','Numara', 'Ad', 'Soyad', 'PÇ1', 'PÇ2', 'PÇ3', 'PÇ4', 'PÇ5', 'PÇ6', 'PÇ7', 'PÇ8','PÇ9', 'PÇ10', 'PÇ11']\n",
    "    new_df = df[cols]\n",
    "\n",
    "    new_df = new_df.assign(**new_df[['Numara']].astype(np.int64))\n",
    "    \n",
    "    # Return the preprocessed data\n",
    "    return new_df\n",
    "\n",
    "def extract_rows_by_numbers(data_frames, target_numbers):\n",
    "    result_dfs = []\n",
    "\n",
    "    # Iterate through each target number\n",
    "    for target_number in target_numbers:\n",
    "        extracted_rows = []\n",
    "\n",
    "        # Iterate through each data frame\n",
    "        for df in data_frames:\n",
    "            # Filter rows based on the \"Number\" column\n",
    "            filtered_rows = df[df['Numara'] == target_number]\n",
    "\n",
    "            # Append the filtered rows to the list\n",
    "            extracted_rows.append(filtered_rows)\n",
    "\n",
    "        # Concatenate the filtered rows into a new data frame for the current target number\n",
    "        result_df = pd.concat(extracted_rows, ignore_index=True)\n",
    "\n",
    "        # Append the result data frame to the list\n",
    "        result_dfs.append(result_df)\n",
    "\n",
    "    return result_dfs\n",
    "\n",
    "def create_pattern(s):\n",
    "    \"\"\"Given a string that consists of letters followed by digits, creates a pattern to use in regex.\n",
    "\n",
    "    Args:\n",
    "    given_string: A string that consists of only letters followed by digits e.g. \"XYZ123\".\n",
    "\n",
    "    Returns:\n",
    "    A string that represents a compiled regular expression pattern.\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if the given string is a valid string that consists of letters followed by digits.\n",
    "    letters = sum(c.isalpha() for c in s)\n",
    "    numbers = sum(c.isdigit() for c in s)\n",
    "\n",
    "    # Create a regular expression pattern that matches the given string.\n",
    "    pattern = '([A-Za-z]{' + str(letters) + '}\\d{' + str(numbers) + '})'\n",
    "\n",
    "    # Return the compiled regular expression pattern.\n",
    "    return pattern\n",
    "\n",
    "def extract_pattern(input_string, pattern):\n",
    "#     pattern = r'([A-Za-z]{3}\\d{3})'\n",
    "    matches = re.findall(pattern, input_string)\n",
    "    result = ' '.join(matches)\n",
    "    return result\n",
    "\n",
    "def delete_empty_dfs(dataframes, target_list):\n",
    "    deleted_ids = []\n",
    "    filtered_df_list = []\n",
    "\n",
    "    for i, df in enumerate(dataframes):\n",
    "        if df.empty:\n",
    "            deleted_ids.append(target_list[i])\n",
    "        else:\n",
    "            filtered_df_list.append(df)\n",
    "    return filtered_df_list, deleted_ids\n",
    "    \n",
    "def process_student_df(df1, df2):\n",
    "    \"\"\"\n",
    "    Process and merge two DataFrames based on the 'Dersler' column, fill NaN values, and perform data conversions.\n",
    "\n",
    "    Args:\n",
    "        df1 (pd.DataFrame): The first DataFrame containing the 'Dersler' column.\n",
    "        df2 (pd.DataFrame): The second DataFrame to be merged with df1. Ex: result_dfs[0]\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The processed DataFrame with NaN values filled, data type conversions, and 'Ders' column dropped.\n",
    "    \"\"\"\n",
    "    # Merge df1 and df2 using a left join based on the 'Dersler' column in df1 and the 'Ders' column in df2\n",
    "    df_merged = df1[['Dersler']].merge(df2, how='left', left_on='Dersler', right_on='Ders')\n",
    "\n",
    "    # Drop the 'Ders' column from df_merged, as it's no longer needed\n",
    "    df_merged.drop('Ders', axis=1, inplace=True)\n",
    "\n",
    "    # Define a list of columns to fill NaN values with the most common value\n",
    "    columns_to_fill = [\"Numara\", \"Ad\", \"Soyad\"]\n",
    "\n",
    "    # Iterate through the specified columns and replace NaN values with the most common value\n",
    "    for column in columns_to_fill:\n",
    "        most_common_value = df_merged[column].mode().iloc[0]  # Get the most common value\n",
    "        df_merged[column].fillna(most_common_value, inplace=True)\n",
    "\n",
    "    # Fill any remaining NaN values in df_merged with 0\n",
    "    df_merged = df_merged.fillna(0)\n",
    "\n",
    "    # Convert the 'Numara' column to integer data type\n",
    "    df_merged['Numara'] = df_merged['Numara'].astype(np.int64)\n",
    "\n",
    "    return df_merged\n",
    "\n",
    "def calculate_weighted_means(df_values, df_weights):\n",
    "    \"\"\"\n",
    "    Calculate the weighted means of columns in a DataFrame based on values and weights.\n",
    "\n",
    "    Args:\n",
    "        df_values (pd.DataFrame): DataFrame containing values for which weighted means are calculated.\n",
    "        df_weights (pd.DataFrame): DataFrame containing weights for the values.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing the calculated weighted means.\n",
    "    \"\"\"\n",
    "    # Calculate the weighted means for each column\n",
    "    weighted_means = (df_values * df_weights).sum(axis=0) / df_weights.sum(axis=0)\n",
    "\n",
    "    # Convert the Series of weighted means to a DataFrame\n",
    "    weighted_means_df = weighted_means.to_frame().T\n",
    "\n",
    "    # Reset the index if needed\n",
    "    weighted_means_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return weighted_means_df\n",
    "\n",
    "def process_result_dfs_v5(df_students, df_pc_dersler):\n",
    "    \n",
    "    # Get the weights \n",
    "    df_weights = df_pc_dersler.iloc[:, 1:]\n",
    "    \n",
    "    # Create an empty list\n",
    "    df_list = []\n",
    "    \n",
    "    # Iterate over the student dataframes\n",
    "    for df_student in df_students:\n",
    "\n",
    "        if df_student.empty:\n",
    "          print('There is an empty DataFrame')\n",
    "          continue\n",
    "\n",
    "        # Create a temporary list to store student info\n",
    "        temp_list1 = [df_student['Numara'][0],df_student['Ad'][0],df_student['Soyad'][0]]\n",
    "        \n",
    "    \n",
    "        # Values from df_students\n",
    "        df_values = df_student.iloc[:, 4:]\n",
    "        \n",
    "        # Calculate the weighted means for each student\n",
    "        weighted_means = (df_values * df_weights).sum(axis=0) / df_weights.sum(axis=0)\n",
    "        \n",
    "        # Store the weighted means in a list\n",
    "        temp_list2 = list(weighted_means.values)\n",
    "        \n",
    "        # Combine lists for each student\n",
    "        temp_list = temp_list1 + temp_list2\n",
    "        \n",
    "        # List of lists (each sublist has one students info)\n",
    "        df_list.append(temp_list)\n",
    "\n",
    "    # Concatenate the DataFrames\n",
    "    df = pd.DataFrame(df_list)\n",
    "    \n",
    "    df.columns = ['Numara', 'Ad', 'Soyad', 'PÇ1', 'PÇ2', 'PÇ3', 'PÇ4', 'PÇ5', 'PÇ6', 'PÇ7', 'PÇ8', 'PÇ9', 'PÇ10', 'PÇ11']\n",
    "    \n",
    "    # Replace NaN values with zero\n",
    "    df = df.fillna(0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def hide_names(df, columns_to_hide=None):\n",
    "    if columns_to_hide is None:\n",
    "        columns_to_hide = df.columns\n",
    "\n",
    "    def hide_name(name):\n",
    "        return name.lstrip()[0] + '*' * (5) if len(name) > 1 else name\n",
    "    \n",
    "    df_copy = df.copy()\n",
    "    for column in columns_to_hide:\n",
    "        if column in df_copy.columns:\n",
    "            if df_copy[column].dtype == 'object':\n",
    "                df_copy[column] = df_copy[column].apply(hide_name)\n",
    "            elif df_copy[column].dtype == 'int64':\n",
    "                df_copy[column] = df_copy[column].astype(str).apply(hide_name)\n",
    "    return df_copy\n",
    "\n",
    "def append_average_row(df):\n",
    "    # Calculate the average for the specified columns\n",
    "    average_row = {\n",
    "        'Numara': 'ORTALAMA',\n",
    "        'Ad': 'ORTALAMA',\n",
    "        'Soyad': 'ORTALAMA'\n",
    "    }\n",
    "\n",
    "    # Filter out the zero values from the DataFrame before calculating the mean\n",
    "    non_zero_df = df.replace(0, np.nan)\n",
    "\n",
    "    for col in ['PÇ1', 'PÇ2', 'PÇ3', 'PÇ4', 'PÇ5', 'PÇ6', 'PÇ7', 'PÇ8', 'PÇ9', 'PÇ10', 'PÇ11']:\n",
    "        average_row[col] = non_zero_df[col].mean()\n",
    "\n",
    "    # Create a DataFrame from the average_row dictionary\n",
    "    df_average = pd.DataFrame([average_row])\n",
    "    \n",
    "    # Replace NaN values with zero\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    # Concatenate the DataFrames\n",
    "    df = pd.concat([df, df_average], ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c720770",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from process_funcs import *\n",
    "\n",
    "# Create a sidebar\n",
    "st.sidebar.title(\"About\")\n",
    "\n",
    "# Write a description of the project\n",
    "st.sidebar.write(\"This application calculates the rates at which graduates meet their program outcomes.\")\n",
    "\n",
    "st.sidebar.subheader('Instructions', divider='orange')\n",
    "\n",
    "# Add a list of instructions\n",
    "instructions = [\n",
    "    \"Enter a sample course ID\",\n",
    "    \"Upload course evaulation reports.\",\n",
    "    \"Upload the graduation list.\",\n",
    "    \"Upload the course list file.\",\n",
    "    \"Run the code and display results.\",\n",
    "    \"Download the resulting Excel file.\"\n",
    "]\n",
    "for i, instruction in enumerate(instructions,1):\n",
    "    st.sidebar.markdown(f\"{i}. {instruction}\")\n",
    "\n",
    "header = st.container()\n",
    "dataset = st.container()\n",
    "results = st.container()\n",
    "\n",
    "with header:\n",
    "    st.title('Program Objectives Project')\n",
    "    \n",
    "    st.write(\"This application calculates the rates at which graduates meet their program outcomes.\")\n",
    "        \n",
    "    # Create course id pattern\n",
    "    st.markdown(\"**IMPORTANT NOTICE: Before proceeding please provide a sample course id pattern, e.g., CSS210. **\")\n",
    "    with st.form(key='my_form'):\n",
    "        sample_id = st.text_input(label='Enter a sample course ID')\n",
    "        submit_id_button = st.form_submit_button(label='Submit')\n",
    "        \n",
    "#     sample_id = st.text_input('Enter a sample course ID', 'XYZ101')\n",
    "        course_id_pattern = create_pattern(sample_id)\n",
    "    \n",
    "with dataset:\n",
    "    st.subheader('Step 1: Upload Course Evaulation Reports',divider='orange')\n",
    "    \n",
    "    # Sample report DataFrame\n",
    "    ex_report = pd.read_excel('ex_report.xlsx')\n",
    "    \n",
    "    if st.checkbox(\"Display a Sample Course Evaulation Report\", key = 'ex_report'):\n",
    "        st.dataframe(ex_report)\n",
    "   \n",
    "    eval_files = st.file_uploader(\"Choose all the Excel files for course reports\", accept_multiple_files=True, key='file_uploader1')\n",
    "    \n",
    "    st.write(f'{len(eval_files)} files are uploaded.')\n",
    "\n",
    "    st.subheader('Step 2: Upload the Graduation List', divider = 'orange')\n",
    "    \n",
    "    # Sample Grad list DataFrame\n",
    "    ex_grad_list = pd.read_excel('ex_grad_list.xlsx')\n",
    "\n",
    "    if st.checkbox(\"Display a Sample Graduation List\", key = 'ex_grads'):\n",
    "        st.dataframe(ex_grad_list)\n",
    "    \n",
    "    # Create a file uploader\n",
    "    grad_list_file = st.file_uploader(\"Choose an Excel file of graduation list\", key='file_uploader2')\n",
    "    \n",
    "    # Read the uploaded file to a Pandas DataFrame\n",
    "    if grad_list_file is not None:\n",
    "        df_mezun_list = pd.read_excel(grad_list_file)\n",
    "        disp_df = df_mezun_list.style.format(precision=0, thousands='')\n",
    "        # Display the DataFrame\n",
    "        st.write(disp_df)\n",
    "\n",
    "    st.subheader('Step 3: Upload the Course List File', divider = 'orange')\n",
    "    \n",
    "    # Sample Weights DataFrame\n",
    "    ex_weights = pd.read_excel('ex_weights.xlsx')\n",
    "    \n",
    "    if st.checkbox(\"Display a Sample Graduation List\", key = 'ex_weights'):\n",
    "        st.dataframe(ex_weights)\n",
    "    \n",
    "    # Create a file uploader\n",
    "    course_list_file = st.file_uploader(\"Choose the Excel file of Course-Outcome relation\", key='file_uploader3')\n",
    "\n",
    "    # Read the uploaded file to a Pandas DataFrame\n",
    "    if course_list_file is not None:\n",
    "        df_pc_dersler = pd.read_excel(course_list_file)\n",
    "        \n",
    "        # Apply the extract_pattern function to each row in the 'Dersler' column\n",
    "        df_pc_dersler['Dersler'] = df_pc_dersler['Dersler'].apply(lambda x: extract_pattern(x, course_id_pattern))\n",
    "\n",
    "        # Display the DataFrame\n",
    "        st.write(df_pc_dersler)\n",
    "    \n",
    "with results:\n",
    "    if eval_files is not None and grad_list_file is not None and course_list_file is not None:\n",
    "        if st.button(\"Get the Results\", key = 'get_results'):\n",
    "            with st.spinner(\"Loading the results\"):\n",
    "                # Get all excel files in the folder as list of dataframes\n",
    "                all_df = process_excel_files(eval_files, course_id_pattern)\n",
    "\n",
    "                # Preprocess these dataframes\n",
    "                processed_df = [preprocess_data(df) for df in all_df]\n",
    "\n",
    "                # Store the id's in a list\n",
    "                mezun_list = list(df_mezun_list['Öğrenci No'])\n",
    "\n",
    "                # Get result_dfs\n",
    "                result_dfs = extract_rows_by_numbers(processed_df, mezun_list)\n",
    "\n",
    "                # Remove the empty dataframes of students and get which ones are deleted\n",
    "                result_dfs, deleted_ids = delete_empty_dfs(result_dfs, mezun_list)\n",
    "\n",
    "                # Create a dataframe of deleted ones\n",
    "                deleted_df = df_mezun_list[df_mezun_list['Öğrenci No'].isin(deleted_ids)]\n",
    "                deleted_students = deleted_df.copy()\n",
    "                deleted_students = deleted_df.style.format(precision=0, thousands='')\n",
    "                \n",
    "                st.subheader('Students not considered for evaluation', divider = \"orange\")\n",
    "                st.write('These students are not included in the computations because all PC values are zero.')\n",
    "                st.dataframe(deleted_students)\n",
    "\n",
    "                st.subheader('Results', divider = 'orange')\n",
    "                df_students = [process_student_df(df_pc_dersler, df2) for df2 in result_dfs]\n",
    "                df = process_result_dfs_v5(df_students, df_pc_dersler)\n",
    "                df = append_average_row(df)\n",
    "                st.dataframe(df)\n",
    "\n",
    "                st.subheader('Downloading the results as Excel file', divider = 'orange')\n",
    "                # Create a download button\n",
    "                def download_excel(df):\n",
    "                    df.to_excel('dataframe.xlsx', index=False)\n",
    "                    with open('dataframe.xlsx', 'rb') as f:\n",
    "                        data = f.read()\n",
    "                    st.download_button(\n",
    "                        label=\"Download the results\",\n",
    "                        data=data,\n",
    "                        key='download_excel',\n",
    "                        file_name='dataframe.xlsx',\n",
    "                        mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n",
    "                    )\n",
    "\n",
    "                # Call the download button function\n",
    "                download_excel(df)\n",
    "\n",
    "                st.subheader('Data analysis', divider = 'orange')\n",
    "                name = st.selectbox('Select a name:', df['Ad'])\n",
    "                # Print the selected name\n",
    "                st.write('You selected:', name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d55f415",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
